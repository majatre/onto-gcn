{"cells":[{"cell_type":"code","metadata":{"cell_id":"47e6d217-6426-4bc7-a1e8-e99ddc9d3bc2"},"source":"!python --version","execution_count":null,"outputs":[{"name":"stdout","text":"Python 3.7.3\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c666bfc7-f155-4f42-bf32-89015d428b8a"},"source":"import tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib, matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"e0cc3245-c670-47ee-9b3a-ae911aeb3028"},"source":"def discretize(df, bins=200):\r\n    print(f\"Discretizing features into {bins} bins\")\r\n    result = df.copy()\r\n    for feature_name in df.columns:\r\n        result[feature_name] = pd.cut(df[feature_name], bins=bins, labels=range(bins), include_lowest=True)\r\n        # result[feature_name], _ = pd.factorize(cut_result)\r\n    return result\r\n\r\n\r\ndef normalize(df):\r\n    result = df.copy()\r\n    for feature_name in df.columns:\r\n        max_value = df[feature_name].max()\r\n        min_value = df[feature_name].min()\r\n        if max_value != min_value:\r\n          result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\r\n    return result\r\n\r\ndef load_data(task = 'PAM50', subset='all', discrete=False, bins=200):\r\n    if subset == 'all':\r\n        path = \"/datasets/mbdata/MBdata_all.csv\"\r\n    elif subset == 'original':\r\n        path = \"./MBdata_original.csv\"\r\n    df = pd.read_csv(path)\r\n    if task == 'DR':\r\n        df = df[df.DR != '?']\r\n        target = df.pop('DR')\r\n    elif task == 'ER':\r\n        df = df[df.ER_Status != '?']\r\n        target = df.pop('ER_Status')\r\n        labels = {\r\n            'pos': 0,\r\n            'neg': 1\r\n        }\r\n        target = target.apply(lambda x: labels[x])\r\n    elif task == 'iC10':\r\n        df = df[df.iC10 != '?']\r\n        target = df.pop('iC10')\r\n        labels = {\r\n            '4ER-': 4,\r\n            '4ER+': 0\r\n        }\r\n        target = target.apply(lambda x: labels[x] if x in labels else int(x))\r\n    elif task == 'PAM50':\r\n        df = df[df.Pam50Subtype != '?']\r\n        target = df.pop('Pam50Subtype')\r\n        pam50_lables = {\r\n            'Normal': 0,\r\n            'LumA': 1,\r\n            'LumB': 2,\r\n            'Basal': 3,\r\n            'Her2': 4\r\n        }\r\n        target = target.apply(lambda x: pam50_lables[x])\r\n\r\n\r\n    features = df.filter(regex='^GE.*')\r\n    features = features.astype('float64')\r\n    # print(features.shape)\r\n\r\n    if discrete:\r\n        features = discretize(features, bins)\r\n    else:\r\n        features = normalize(features)\r\n        features.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\r\n    return features, target","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiments","metadata":{"tags":[],"cell_id":"8ab79027-c34f-4165-b509-0e26347aa8b3"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"8e118739-247b-4871-ac13-04d94a8bb14f"},"source":"from sklearn.ensemble import RandomForestClassifier\r\nimport numpy as np\r\nfrom sklearn import metrics\r\nfrom sklearn.model_selection import cross_validate, KFold, StratifiedKFold, train_test_split\r\nimport random\r\n\r\nimport warnings\r\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f4a559db-feaa-467f-9d80-b340b35c6cfc"},"source":"genes_50 = pd.read_csv(\"Parker_centroids.txt\", sep=\"\\t\")\r\ngenes_50 = [\"GE_\"+ g for g in list(genes_50.IlluminaID)]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"4d9e20a6-b40d-4eb0-a9b5-8fe0a1bcc757"},"source":"features, target = load_data(task='PAM50', subset='all', discrete=False)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e93e7b9a-c02a-4af4-a6ec-7db56733c9d6"},"source":"genes_50 = [g for g in genes_50 if g in (features.columns)]\r\nfeatures = features[genes_50]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"122ff653-0f0d-45df-a4fd-c7cb7894f610"},"source":"acc = []\r\n\r\nfor seed in range(5):\r\n    X_train, X_test, y_train, y_test = train_test_split(features, \r\n                                                        target.to_numpy(), \r\n                                                        stratify=target.to_numpy(),\r\n                                                        train_size=1500,\r\n                                                        test_size=400,\r\n                                                        shuffle=True,\r\n                                                        random_state=seed\r\n                                                        )\r\n    rf = RandomForestClassifier()\r\n    rf.fit(X_train, y_train)\r\n    y_pred=rf.predict(X_test)\r\n    score = metrics.accuracy_score(y_pred, y_test)\r\n    print(score)\r\n    acc.append(score)\r\n\r\nprint(f\"{np.mean(acc):.3f}+-{np.std(acc):.3f}\")","execution_count":null,"outputs":[{"name":"stdout","text":"0.825\n0.8225\n0.8325\n0.8375\n0.805\n0.824+-0.011\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"bf846c6f-d1a1-41b0-80f0-bf8b1de5a238"},"source":"import sklearn.svm\r\n\r\nacc = []\r\nkf = StratifiedKFold(n_splits=5, shuffle=True)\r\n\r\nx_train = features.values[:]\r\ny_train = target.values[:]\r\n\r\nfor C in [0.01, 0.1, 1, 100]:\r\n    for train, valid in kf.split(x_train, y_train):\r\n        svm = sklearn.svm.SVC(kernel='rbf', C=C)\r\n        svm.fit(x_train[train], y_train[train])\r\n        y_pred=svm.predict(x_train[valid])\r\n        acc.append(metrics.accuracy_score(y_train[valid], y_pred))\r\n        print(f\"C={C}: {acc[-1]:.3f}\")\r\n\r\n    print(f\"C={C}: {np.mean(acc):.3f}+-{np.std(acc):.3f}\")","execution_count":null,"outputs":[{"name":"stdout","text":"C=0.01: 0.572\nC=0.01: 0.562\nC=0.01: 0.570\nC=0.01: 0.572\nC=0.01: 0.546\nC=0.01: 0.564+-0.010\nC=0.1: 0.797\nC=0.1: 0.810\nC=0.1: 0.813\nC=0.1: 0.808\nC=0.1: 0.830\nC=0.1: 0.688+-0.124\nC=1: 0.856\nC=1: 0.815\nC=1: 0.861\nC=1: 0.843\nC=1: 0.838\nC=1: 0.739+-0.125\nC=100: 0.800\nC=100: 0.825\nC=100: 0.823\nC=100: 0.853\nC=100: 0.802\nC=100: 0.760+-0.114\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"20696d87-e700-46e3-a291-276347e1023f"},"source":"from sklearn.svm import SVC\r\nfrom sklearn.model_selection import GridSearchCV\r\n\r\nacc_all = []\r\nkf = StratifiedKFold(n_splits=5, shuffle=True)\r\n\r\nx_train = features.values[:]\r\ny_train = target.values[:]\r\n\r\nfor train, valid in kf.split(x_train, y_train):\r\n    params = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\r\n    classifier = GridSearchCV(SVC(gamma=\"scale\"), params, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\r\n        \r\n    classifier.fit(x_train[train], y_train[train])\r\n    Y_pred = classifier.predict(x_train[valid])\r\n    acc = metrics.accuracy_score(y_train[valid], Y_pred)\r\n    acc_all.append(acc)\r\n    print(f\"{acc:.3f}\")\r\n\r\nprint(f\"{np.mean(acc):.3f}+-{np.std(acc):.3f}\")","execution_count":null,"outputs":[{"name":"stdout","text":"0.828\n0.868\n0.853\n0.851\n0.827\n0.827+-0.000\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"3aa09c0e-d008-439e-b7aa-5a406530e112"},"source":"for bins in [200,100,10,20]:\r\n    features, target = load_data(task='DR', subset='all', discrete=False, bins=bins)\r\n    acc = []\r\n\r\n    \r\n    for seed in range(5):\r\n        X_train, X_test, y_train, y_test = train_test_split(features, \r\n                                                            target.to_numpy(), \r\n                                                            stratify=target.to_numpy(),\r\n                                                            train_size=1500,\r\n                                                            test_size=400,\r\n                                                            shuffle=True,\r\n                                                            random_state=seed\r\n                                                            )\r\n        rf = RandomForestClassifier()\r\n        rf.fit(X_train, y_train)\r\n        y_pred=rf.predict(X_test)\r\n        score = metrics.accuracy_score(y_pred, y_test)\r\n        print(score)\r\n        acc.append(score)\r\n\r\n    print(f\"{np.mean(acc):.3f}+-{np.std(acc):.3f}\")","execution_count":null,"outputs":[{"name":"stdout","text":"0.69\n0.6775\n0.6975\n0.7\n0.675\n0.688+-0.010\n0.685\n0.6925\n0.6875\n0.6975\n0.6975\n0.692+-0.005\n0.7025\n0.6925\n0.6925\n0.685\n0.6925\n0.693+-0.006\n0.685\n0.685\n0.6875\n0.7025\n0.6925\n0.691+-0.007\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"23b075e4-d13a-4f32-b9af-db813dc76b4b"},"source":"# for bins in [200,100,10,20]:\r\n#     features, target = load_data(task='DR', subset='original', discrete=True, bins=bins)\r\nacc = []\r\nfeatures_local = features.copy().astype('float64')\r\n# features_local = features_local['GE_ESR1', 'GE_ERBB2', 'GE_AURKA' ]\r\n# n=1000\r\n# embeddings='dl2vec'\r\n# cos_distances_sorted = load_gene_embeddings(name=embeddings, reference_gene='FOXA1')\r\n# top_genes = ['GE_'+g for g,v in cos_distances_sorted.items() if 'GE_'+g in list(features.columns)]\r\n# features_local = features_local.filter(top_genes[:n]) #features_o.columns)\r\n\r\nfor seed in range(5):\r\n    X_train, X_test, y_train, y_test = train_test_split(features_local.to_numpy(), \r\n                                                        target.to_numpy(), \r\n                                                        stratify=target.to_numpy(),\r\n                                                        train_size=1500,\r\n                                                        test_size=400,\r\n                                                        shuffle=True,\r\n                                                        random_state=seed\r\n    )\r\n    num_labels = 5\r\n    # y_train = target.values[:]\r\n    b = np.zeros((y_train.size, num_labels))\r\n    b[np.arange(y_train.size),y_train] = 1\r\n    y_train = b\r\n\r\n    b = np.zeros((y_test.size, num_labels))\r\n    b[np.arange(y_test.size),y_test] = 1\r\n    y_test = b\r\n\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Dense(64, activation='relu'),\r\n        # tf.keras.layers.Dropout(0.2),\r\n        # tf.keras.layers.Dense(256, activation='relu'),\r\n        # tf.keras.layers.Dense(64, activation='relu'),\r\n        tf.keras.layers.Dense(64, activation='relu'),# use_bias=False),\r\n        #tf.keras.layers.BatchNormalization(),\r\n        # tf.keras.layers.Activation(\"relu\"),\r\n        tf.keras.layers.Dense(num_labels, activation='softmax')\r\n    ])\r\n\r\n    adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\r\n    model.compile(optimizer=adam,\r\n                    loss='categorical_crossentropy',\r\n                    metrics=['accuracy'])\r\n\r\n\r\n    model.fit(X_train, y_train, epochs=50,  verbose=0)\r\n    model.evaluate(X_test, y_test, verbose=2)\r\n    y_pred=model.predict(X_test)\r\n    y_pred=np.argmax(y_pred, axis=1)\r\n    score = metrics.accuracy_score(np.argmax(y_test, axis=1), y_pred)\r\n    acc.append(score)\r\n\r\nprint(f\"{np.mean(acc):.3f}+-{np.std(acc):.3f}\")","execution_count":null,"outputs":[{"name":"stdout","text":"13/13 - 0s - loss: 0.4326 - accuracy: 0.8350\n13/13 - 0s - loss: 0.3981 - accuracy: 0.8425\n13/13 - 0s - loss: 0.4192 - accuracy: 0.8350\n13/13 - 0s - loss: 0.4215 - accuracy: 0.8350\n13/13 - 0s - loss: 0.4563 - accuracy: 0.8075\n0.831+-0.012\n","output_type":"stream"}]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_execution_queue":[],"deepnote_notebook_id":"2ed9bf6c-aa74-475b-870b-ce5f9b5034d4"}}